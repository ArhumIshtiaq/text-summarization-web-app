[11]
Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism,[12][13] followed by disappointment and the loss of funding (known as an "AI winter"),[14][15] followed by new approaches, success and renewed funding. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields. [13] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began. [53] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! [73] Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task. [b] A complex algorithm is often built on top of other, simpler, algorithms. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". The functional model refers to the correlating data to its computed counterpart. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. [103] The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge[104] by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). [118] However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. [123] Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". Natural language processing[126] (NLP) allows machines to read and understand human language. Some straightforward applications of natural language processing include information retrieval, text mining, question answering[127] and machine translation. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". Applications include speech recognition,[132] facial recognition, and object recognition. [133] Computer vision is the ability to analyze visual input. [136] A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. [147][148][149] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal affect analysis (see multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject. No established unifying theory or paradigm guides AI research. Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering? [179]
Much of traditional GOFAI got bogged down on ad hoc patches to symbolic computation that worked on their own toy models but failed to generalize to real-world results. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. As such, there is a need for policy making to devise policies for and regulate artificial intelligence and robotics. Some question whether this kind of check could actually remain in place. Human information processing is easy to explain, however human subjective experience is difficult to explain. For example, consider what happens when a person is shown a color swatch and identifies it, saying "it's red". The hard problem is that people also know something else—they also know what red looks like. (Consider that a person born blind can know that something is red without knowing what red looks like. Science fiction writer Vernor Vinge named this scenario "singularity". making diagnosis more  precise,  enabling  better  prevention  of  diseases), increasing  the  efficiency  of  farming, contributing  to climate  change mitigation  and  adaptation, [and] improving  the  efficiency  of production systems through predictive maintenance", while acknowledging potential risks. [239][240][241] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology.