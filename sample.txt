The given research article ‘A general reinforcement learning Algorithm that Masters Chess, Shogi and Go through self-play’ is written by a group of researchers at deepMind with David Silver as the lead author. Rest of the team include Thomas Hubert, Julian Schrittwiser, Ioannis Antonoglou, Mathew Lai Arthur Guex, Mare Lanchot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis. The article was published in the American Association of the Advancement of Science in December 2018. The paper focuses on highlighting an algorithm called AlphaZero which is used to make a computer agent learn how to play chess , shogi and Go using only self play and without feeding in the knowledge about the environment of each individual game. The paper goes deep in the mathematical algorithm and also compares the performance of it with several other algorithms. 

The lead author of the paper, David Silver is the lead of a group of researchers in deepMind and has the most number of publications to his name in deepMind.  His major field of research has always been around optimizing and enhancing the game-play algorithms through reinforcement learning. During his phD he co-introduced the algorithm used in master lever 9x9 Go program, his version of MoGo was one of the most powerful go programs as of  2009. Not only David as an individual has worked towards enhancement of AI rather the group of researchers at deepMind have made significant contributions to the AI community and helped many organizations, namely Google in improving and developing powerful algorithms and models too. They made notable contributions towards improving the accuracy of recommendations for  digital goods and helped increase the battery life of smartphones. 

Silver himself has mentioned his motivation behind his research, which is majorly focused around reinforcement learning, is to analyze whether a computer can mimic human behaviour to a point where it can completely learn on its own without any human intervention. He wanted to not only understand the intelligence of a human but also mimic its behaviour in a computer agent. AlphaZero is considered one of the major breakthroughs in the game-playing algorithms  because of its capability to not only play one game optimally but to excel in multiple games like chess, shogi and  Go without having to be explicitly programmed to play individual games.

AlphaZero is not only celebrated for its ability to adapt to play multiple games but also due to its efficiency which is far better than the previous game playing algorithms. The paper highlights its comparison between approaches like Stockfish algorithm for playing chess, Elmo algorithm for playing shogi and AlphaLee algorithm for playing Go. All of the experiments concluded that just within hours of training AlphaZero was able to outshine all the above mentioned algorithms in playing each game with utmost efficiency. It moves away from the exhaustive method of considering millions of positions before making a move and only considers a few thousand based on the most probable scenarios. 

Although the paper shows experimental based evidence to claim the generalization of the algorithm for playing games but all the games under experimentation were two player games whereas the hypothesis claims that it has the ability to learn and adapt to multiple player  games. The paper does not mention any research conducted to see how the algorithm would perform on games with more than  two players. 
